ğŸ“° Full-Stack News Chatbot with Qdrant + Gemini/OpenAI

This project is a full-stack AI chatbot where users can interact with a knowledge base of news articles. It uses React.js for the frontend, Node.js + Express for the backend, Redis for caching, and Qdrant for vector search with embeddings generated from Gemini (Google AI) or OpenAI.

ğŸš€ Features

âœ… Real-time chat interface (React.js)

âœ… REST API (Express.js backend)

âœ… Embedding generation using Gemini API or OpenAI API

âœ… Vector similarity search with Qdrant

âœ… Caching with Redis

âœ… Automatic creation of news_collection in Qdrant

âœ… Auto-load of news articles into Qdrant on startup

ğŸ“‚ Project Structure
project/
â”‚â”€â”€ backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ routes/       # Express routes
â”‚   â”‚   â”œâ”€â”€ services/     # Qdrant + Embedding services
â”‚   â”‚   â””â”€â”€ server.js     # Main backend entry
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ .env
â”‚
â”‚â”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/   # React components (ChatWindow, MessageList, etc.)
â”‚   â”‚   â””â”€â”€ App.js
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ .env
â”‚
â””â”€â”€ README.md

âš™ï¸ Tech Stack

Frontend

React.js (with create-react-app)

Axios for API calls

WebSocket for live chat updates

Backend

Node.js + Express.js

Redis (message cache / history)

Qdrant (vector database for semantic search)

Gemini / OpenAI for embeddings & responses

ğŸ”§ Setup Instructions
1ï¸âƒ£ Clone Repository
git clone https://github.com/your-username/news-chatbot.git
cd news-chatbot

2ï¸âƒ£ Backend Setup
cd backend
npm install


Create .env in backend/:

PORT=4000

# Choose one provider:
GEMINI_API_KEY=your_google_ai_api_key_here
# or
OPENAI_API_KEY=your_openai_api_key_here

QDRANT_URL=https://your-cluster-id.gcp.cloud.qdrant.io:6333
QDRANT_API_KEY=your_qdrant_api_key

REDIS_URL=redis://localhost:6379


Run backend:

npm run dev


Backend will auto-create news_collection in Qdrant.

3ï¸âƒ£ Frontend Setup
cd frontend
npm install


Create .env in frontend/:

REACT_APP_API_URL=http://localhost:4000


Run frontend:

npm start

ğŸ§  How It Works

User sends a chat message from the React app.

Backend generates an embedding for the message.

Embedding is searched in Qdrant (news_collection).

Relevant news articles are retrieved.

Gemini/OpenAI generates a response using context from the articles.

Response is cached in Redis & sent back to frontend.

ğŸ›  Troubleshooting

500 Internal Server Error â†’ Check backend logs, may be due to missing API key.

429 Quota exceeded â†’ Your Gemini key hit free limits. Switch to OpenAI or enable billing.

404 Collection not found â†’ Restart backend, it auto-creates news_collection.

Redis connection error â†’ Ensure Redis is running locally (redis-server).

ğŸ“Œ Roadmap

 Authentication & user accounts

 Admin panel for uploading news

 Support for multiple collections (sports, finance, etc.)

 Deploy on cloud (Render / Vercel + Railway)

ğŸ“ License

MIT License Â© 2025 Your Name
